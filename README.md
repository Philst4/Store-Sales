# ğŸ“¦ Store Sales Forecasting Pipeline
End-to-End Machine Learning Project

This repository contains a fully reproducible ML pipeline for the **Kaggle Store Sales Forecasting** competition. It demonstrates practical skills across **data engineering**, **ML model development**, **hyperparameter optimization**, **experiment reproducibility**, and **deployment-style automation**.

The project can be run via:

<<<<<<< HEAD
# Setting project up locally
- Clone project (maybe download git?)
- Navigate to project root directory in terminal
- Install conda before if necessary
- Make environment called 'store-sales' with environment.yml; activate it
=======
1. **Google Colab** (easiest)
2. **Locally via terminal scripts**
3. **Locally via Jupyter notebook**
>>>>>>> 73b7680990bf49b144b49d08050a9f5ab74f6729

---

## ğŸš€ Project Overview

<<<<<<< HEAD
# Running project from terminal (locally)
(1) python scripts/process_data.py
=======
This pipeline covers the full workflow:

**Raw data â†’ Feature engineering â†’ Hyperparameter tuning â†’ Model training â†’ Submission file generation**
>>>>>>> 73b7680990bf49b144b49d08050a9f5ab74f6729

Key components:

- **Data preprocessing & feature engineering**  
- **XGBoost / LightGBM model training**  
- **Optuna hyperparameter tuning**  
- **Modular, script-based architecture**  
- **Environment-managed reproducibility (conda)**  
- **Notebook and CLI execution**

This project reflects real-world workflows for **Data Science**, **Machine Learning Engineering**, and **Software Engineering** roles.

---

## ğŸ§± Project Structure

```
Store-Sales/
â”œâ”€â”€ data/                 # Raw & processed datasets (ignored via .gitignore)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ process_data.py   # Cleans + engineers features
â”‚   â”œâ”€â”€ tune_model.py     # Runs Optuna study
â”‚   â”œâ”€â”€ train_best.py     # Trains final model using best trial
â”‚   â””â”€â”€ make_submission.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ pipeline_local.ipynb
â”‚   â””â”€â”€ pipeline_colab.ipynb
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Setup

### 1. ğŸ“¥ Google Colab (Easiest)

1. Open **`pipeline_colab.ipynb`** in Colab.  
2. Run all cells â€” the notebook handles dependencies, dataset download, and pipeline execution.

_No local setup required._

---

### 2. ğŸ–¥ï¸ Local Setup (Terminal)

#### Step 1 â€” Clone the repository

```bash
git clone https://github.com/Philst4/Store-Sales.git
cd Store-Sales
```

#### Step 2 â€” Create and activate conda environment

```bash
conda env create -f environment.yml
conda activate store-sales
```

#### Step 3 â€” Run the pipeline

```bash
# 1ï¸âƒ£ Data processing & feature engineering
python scripts/process_data.py

# 2ï¸âƒ£ Hyperparameter tuning with Optuna
python scripts/tune_model.py

# 3ï¸âƒ£ Train best model
python scripts/train_best.py

# 4ï¸âƒ£ Generate submission
python scripts/make_submission.py
```

Output directories:

```
data/processed/
models/
submissions/submission.csv
optuna_studies.db
```

---

### 3. ğŸ§ª Notebook Execution (Local)

1. Open **`pipeline_local.ipynb`**  
2. Activate conda environment  
3. Run cells top-to-bottom (mirrors CLI workflow)

---

## ğŸ“Š Technologies Used

- Python  
- XGBoost / LightGBM  
- Optuna  
- Pandas / NumPy  
- Matplotlib / Seaborn  
- Conda (reproducibility)  
- Jupyter / Google Colab

---

## ğŸ¯ Skills Demonstrated

**Machine Learning:**

- Feature engineering  
- Hyperparameter optimization (Optuna)  
- Cross-validation & evaluation strategies  

**Software Engineering:**

- Modular, maintainable Python scripts  
- Reproducible environments  
- Clear project structure  
- Automated pipelines  

**End-to-End Deployment Thinking:**

- Reproducible local + cloud execution  
- Script-driven workflow (production-like)  
- Clear, professional pipeline for reviewers/interviews  

---

## ğŸ“ Notes

- Dataset comes from **Kaggle Store Sales Forecasting** competition.  
- Data folders are excluded via `.gitignore`; the scripts/notebooks download or generate necessary files automatically.

<<<<<<< HEAD
(4) python scripts/make_submission.py

# Running project using local notebook 'pipeline_local.ipynb'
Run cells in notebook

# Running project using Colab notebook 'pipeline_colab.ipynb'
Run cells in notebook
=======
>>>>>>> 73b7680990bf49b144b49d08050a9f5ab74f6729
